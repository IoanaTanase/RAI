# EU AI Act

## Scope, purpose and timing 

The EU AI Act is a comprehensive regulatory framework that applies across all sectors, geographical regions, AI value chain stages, and types of AI systems and models, ensuring end-to-end compliance within the EU market and beyond.

The EU AI Act aims to ensure the safety, fundamental rights, legal certainty, and innovation in AI, fostering a unified market and employing a risk-based approach for proportional regulation.

The AI Act will apply to:
- Deployers within the EU;
- Providers selling AI systems or general-purpose AI models in the EU, regardless of their location;
- Importers and distributors in the EU market;
- Product manufacturers for AI systems under their name or trademark in the EU;
- Providers and deployers whose AI system outputs are used in the EU;
- Persons in the EU affected by AI systems.

### Timeline

- The AI Act will become effective on August 1, 2024.
- Obligations for prohibited AI systems and those related to AI literacy will start on February 2, 2025.
- Specific obligations for general-purpose AI models will begin on August 2, 2025.
- Most obligations, including those for high-risk AI systems under Annex III and systems with specific transparency requirements, will apply from August 2, 2026.
- Obligations for high-risk systems in Annex I will take effect on August 2, 2027.

### Penalties 

Market Surveillance Authorities can impose significant fines under the AI Act for non-compliance:
- Up to €35 million or 7% of worldwide annual turnover for prohibited AI systems.
- Up to €15 million or 3% of worldwide annual turnover for most other obligations.
- Up to €7.5 million or 1% of worldwide annual turnover for supplying incorrect information.
- Additionally, the European Commission can fine providers of general-purpose AI models up to €15 million or 3% of worldwide annual turnover.

Complaints regarding AI Act infringements can be submitted to a Market Surveillance Authority.

## Terminology 

**AI System** == a machine-based system designed to operate with autonomy and adaptiveness, generating outputs like predictions, recommendations, or decisions based on the input it receives.

**General-Purpose AI Mode** -= performs various tasks competently, is integrated into different systems or applications, and is not limited to research or prototyping activities.

**Provider** == An entity that develops or markets an AI system or model, placing it on the market or putting it into service under its own name or trademark.

**Deployer** ==  An entity using an AI system under its authority, except when used for personal non-professional activities.

## Provisions

The Act classifies Al systems based on their risk levels:
- Unacceptable systems that are banned
- High with strict regulations
- Limited with lighter transparency obligations
- Minimal and mostly unregulated

<img width="226" alt="image" src="https://github.com/user-attachments/assets/20265bcc-47cf-4638-9d62-d06ad484e605" />
Source: MSFT on the Issues 

### Prohibited AI Systems

- Subliminal and Manipulative Techniques: AI systems that covertly influence human behavior, hindering individuals from making informed decisions and causing significant harm
- Exploitation of Vulnerable Persons: AI systems designed to exploit vulnerabilities in specific groups, such as children or individuals with disabilities
- Social Scoring: The use of AI systems to assess or classify individuals based on their social behavior, potentially leading to detrimental social scoring
- Emotion Inference in Sensitive Areas: AI systems that infer emotions within sensitive settings, such as workplaces or educational institutions, are prohibited unless utilized for legitimate medical or safety reasons.
- Biometric Data Misuse: AI systems that misuse biometric data to deduce or infer sensitive attributes, such as race, political affiliations, religious beliefs, or philosophical views, are banned. However, this prohibition does not apply to the lawful labeling or filtering of biometric datasets for law enforcement purposes.
- Untargeted Facial Recognition: The creation or expansion of facial recognition databases through untargeted image scraping from the internet or CCTV footage is prohibited.
- Real-Time Remote Biometric Identification in Public Spaces for Law Enforcement: Generally prohibited, these systems may only be deployed in public spaces for law enforcement under specific, narrowly defined circumstances.

### High risk AI Systems

High-risk AI systems are those that present significant risks to individuals' rights and freedoms. The AI Act identifies two categories of high-risk AI systems.
The first category includes AI systems that are high-risk under EU harmonization legislation. These systems are high-risk when they are either a safety component of a product or the product itself, and require third-party conformity assessment. Examples include AI used in machinery, toys, lifts, medical devices, and vehicles.
The second category includes AI systems used for specific high-risk tasks, as listed in Annex III of the AI Act. These tasks include:
- Biometrics: Remote biometric identification, biometric categorization, and emotion recognition.
- Critical Infrastructure: Safety components in digital infrastructure management, road traffic, and utility supply.
- Education: AI determining access to education or evaluating learning outcomes.
- Employment: Recruitment, task allocation, performance monitoring, and decision-making in employment relationships.
- Essential Services: Credit evaluation, emergency call classification, and risk assessment in life and health insurance.
Additionally, certain AI systems used in law enforcement, migration, asylum, border management, justice administration, and democratic processes are considered high-risk.

Obligations of providers:
- Implementing a risk management and quality management system
- Data governance and bias mitigation
- Maintaining technical documentation
- Record-keeping and traceability
- Ensuring human oversight and system accuracy
- Complying with registration and conformity assessment
- Providing contact information and affixing the “CE marking”

Obligations of deployers: 
- Assigning trained human oversight
- Ensuring relevant input data
- Informing impacted individuals and workers
- Conducting fundamental rights impact assessments for specific uses
- Providing explanations of AI's role in decision-making

### Systems with transparency requirements

AI systems that may mislead end-users and must follow specific transparency rules. They include:
- AI systems interacting with individuals
- AI systems generating synthetic content
- Emotion recognition systems
- Biometric categorization systems
- Deep fake content generators
- Text generators informing the public
  
The obligations on providers and deployers depend on the particular AI system in question. These obligations may include disclosure requirements, labelling requirements, and transparency requirements with respect to the user.

### General-Purpose AI models

General-purpose AI models are uniquely regulated due to their broad application potential. The AI Act imposes obligations on providers of these models, including:
•	Keeping updated technical documentation, detailing training and testing processes, and providing it to authorities on request.
•	Providing up-to-date information for AI system providers who use these models.
•	Complying with EU copyright laws.
•	Publishing a summary of the content used for model training.

Models posing systemic risks face stricter requirements, such as ensuring cybersecurity and assessing risks at an EU level. Currently, only the most advanced models are considered potentially systemic risks.

## Holistic measures to consider

- Inventory AI systems: List all AI systems used in your organisation.
- Risk-assess AI use cases: Evaluate each AI use case for compliance with the EU AI Act, focusing on risks and ethics.
- Perform AI readiness assessment: Identify governance gaps and improvement areas by assessing AI capabilities and practices.
- Adopt Responsible AI principles: Apply ethical guidelines to ensure responsible AI development and use, aligned with laws and societal expectations.
- Roll out AI upskilling programme: Educate your workforce on EU AI Act requirements and responsible AI principles to promote compliance and ethical practices.

## Additional resources and sources

https://blogs.microsoft.com/on-the-issues/2025/01/15/innovating-in-line-with-the-european-unions-ai-act/

https://natlawreview.com/article/understanding-eu-ai-act

https://www.pwc.ie/services/workforce/insights/eu-ai-act-navigate-prohibited-ai.html

